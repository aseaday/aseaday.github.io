---
title: "CUDA HyerIntro"
classes: wide
date: 2023-03-20
categories:
  - blog
tags:
  - developer
---

## 硬件

## CUDA

CUDA 是 Compute Unified Device Architecture (统一计算设备架构)的缩写。根据上下文，"CUDA"可以指代多个不同的概念:一个高级设备架构、一个基于该设计的并行编程模型，或是一个扩展了 C 等高级语言以添加该编程模型的软件平台。

CUDA 的愿景在 [Lindholm 等人 2008 年的白皮书](https://www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/readings/lindholm08_tesla.pdf)中有详细阐述。我强烈推荐这篇论文，它是 NVIDIA 文档中许多说法、图表，甚至特定措辞的原始来源。


在这里，主要关注 CUDA 的设备架构部分。"CUDA"的核心特征是相对于之前的 GPU 架构而言的简单性。

在 GeForce 8800 和由此衍生的 Tesla 数据中心 GPU 之前，NVIDIA 的 GPU 采用了复杂的管线着色器架构，将软件着色器阶段映射到异构的专用硬件单元上。这种架构对软件和硬件双方都带来了挑战:它要求软件工程师将程序映射到固定管线上，并迫使硬件工程师去猜测管线各步骤之间的负载比例。

![固定管线设备架构(G71)示意图。注意用于处理片段和顶点着色的独立处理器组](/images/light-fixed-pipeline-g71.svg)

具有统一架构的 GPU 设备要简单得多：硬件单元完全统一，每个单元都能执行广泛的计算任务。这些单元被称为流式多处理器（Streaming Multiprocessors，简称 SMs），其主要子组件是 CUDA 核心（CUDA Cores）和（在最新的 GPU 中）张量核心（Tensor Cores）。


![统一计算设备架构(G80)的示意图。没有不同类型的处理器, 所有有意义的计算都发生在图中央完全相同的流式多处理器中，这些处理器接收顶点、几何和像素线程的指令](/images/light-cuda-g80.svg)

关于 CUDA 硬件架构的历史和设计，Fabien Sanglard 的[这篇博文](https://fabiensanglard.net/cuda/)提供了一个易于理解的入门介绍。该博文引用了一些高质量的参考资料，如 NVIDIA 的 Fermi 计算架构白皮书。 另外值得一提的事，Lindholm 等人在 2008 年发表的介绍[Tesla 架构的白皮书](https://images.nvidia.com/content/pdf/tesla/whitepaper/pascal-architecture-whitepaper.pdf)。NVIDIA 的 Tesla P100 白皮书虽然不那么学术化，但记录了一些对当今大规模神经网络工作负载至关重要的特性，如 NVLink 和片上高带宽内存。

## SM

当我们编程 GPU 时,我们会产生一系列指令供其流式多处理器执行。

![SM 的示意图](/images/light-gh100-sm.svg)

下图展示了 H100 GPU 中流式多处理器的内部架构。GPU 核心以绿色显示,其他计算单元为褐红色,调度单元为橙色,内存为蓝色。此图改编自 NVIDIA 的 H100 白皮书。

NVIDIA GPU 的流式多处理器(SM)大致类似于 CPU 的核心。也就是说,SM 既执行计算,又在寄存器中存储可用于计算的状态,并配有相关的缓存。与 CPU 核心相比,GPU 的 SM 是相对简单且性能较弱的处理器。SM 中的执行在指令内部是流水线化的(如同 1990 年代以来的几乎所有 CPU),但没有推测执行或指令指针预测功能(这与当今所有高性能 CPU 不同)。

然而,GPU 的 SM 可以并行执行更多线程。

作为对比:AMD EPYC 9965 CPU 最大功耗为 500W,有 192 个核心,每个核心同时最多可以执行两个线程的指令,总共可并行 384 个线程,每个线程大约消耗 1.25W 功率。

H100 SXM GPU 最大功耗为 700W,有 132 个 SM,每个 SM 有 4 个线程束调度器,每个调度器每个时钟周期可以并行地向 32 个线程(即一个线程束)发出指令,总共可以并行超过 16,000 个线程,每个线程仅消耗约 0.05W。需要注意的是,这是真正的并行:16,000 个线程中的每一个都可以在每个时钟周期取得进展。

GPU 的 SM 还支持大量并发线程 -- 即那些指令交错执行的线程。
H100 上的单个 SM 可以并发执行多达 2048 个线程,这些线程被分成 64 个线程组,每组 32 个线程。有了 132 个 SM,总共可以支持超过 250,000 个并发线程。

CPU 也可以并发运行许多线程。但在 GPU 上,线程束之间的切换发生在单个时钟周期内(比 CPU 上的上下文切换快 1000 多倍),这同样得益于 SM 的线程束调度器。大量可用的线程束和快速的线程束切换有助于隐藏内存读取、线程同步或其他耗时指令造成的延迟,确保计算资源(特别是 CUDA 核心和张量核心)得到充分利用。

这种延迟隐藏是 GPU 优势的关键。CPU 试图通过维护大型的硬件管理缓存和复杂的指令预测来对终端用户和程序员隐藏延迟。这些额外的硬件限制了 CPU 可以分配给计算的硅面积、功率和散热预算的比例。

GPU 相比 CPU 将更多的面积用于计算(绿色),而用于控制和缓存(橙色和蓝色)的面积较少。此图改编自 Fabien Sanglard 的博客,该博客可能也改编自 CUDA C 编程指南中的图表。

对于神经网络推理或顺序数据库扫描等程序或功能,程序员相对容易表达缓存的行为(例如,存储每个输入矩阵的一个块,并将其保持在缓存中足够长的时间以计算相关输出),最终结果是获得了更高的吞吐量。